# Root Cause Analysis - Memory Leak Issue

## üîç Problem Investigation

### Initial Symptoms
- **Error Message**: `FATAL ERROR: invalid table size Allocation failed`
- **Memory Growth**: Unbounded heap growth to 1400MB+
- **Trigger**: Laravel Scout driver integration tests with large batch operations
- **Impact**: Complete server crashes during indexing

### Memory Profiling Results

#### Before Fix
```
Heap Usage Pattern:
0 min:    50MB  (startup)
5 min:   200MB  (light indexing)
10 min:  600MB  (batch operations)
15 min: 1200MB  (approaching limit)
20 min: CRASH   (OOM error)
```

#### Memory Growth Hotspots Identified
1. **InMemoryTermDictionary**: Unbounded Map growth
2. **JSON.stringify()**: Massive object serialization
3. **Posting Lists**: Unlimited document entries per term
4. **Term List**: No size constraints on stored terms

## üß¨ Technical Root Causes

### 1. Unbounded Cache Growth
```typescript
// PROBLEM: No size limits
private termDictionary: Map<string, PostingList> = new Map();

// Impact: Unlimited term storage leading to memory exhaustion
```

### 2. Massive JSON Serialization
```typescript
// PROBLEM: Serializing huge objects without size checks
JSON.stringify(this.termDictionary);

// Impact: Memory spikes during serialization operations
```

### 3. Posting List Accumulation
```typescript
// PROBLEM: No limits on posting list size
postingList.addEntry(entry); // Could grow to thousands of entries

// Impact: Individual terms consuming excessive memory
```

### 4. Memory Pressure Ignorance
- No monitoring of heap usage
- No automatic cleanup mechanisms
- No eviction strategies for old data

## üìä Memory Allocation Analysis

### Object Size Breakdown (Pre-Fix)
- **Term Dictionary Map**: 800MB+ for 50K terms
- **Posting Lists**: 400MB+ for position arrays
- **JSON Serialization Buffer**: 300MB+ temporary allocation
- **Other Objects**: 100MB+ (normal application usage)

### Memory Leak Patterns
1. **Additive Growth**: Each new term permanently increased memory
2. **Multiplicative Effect**: Large documents created massive posting lists
3. **Serialization Spikes**: JSON operations caused temporary 2x memory usage
4. **Garbage Collection Failure**: Objects held by references couldn't be collected

## üî¨ Debugging Methodology

### Tools Used
- `process.memoryUsage()` for heap monitoring
- Custom memory tracking in term dictionary
- Performance profiling during Laravel Scout tests
- Memory snapshots at different indexing stages

### Key Findings
1. **Term Dictionary** was the primary memory consumer
2. **Serialization operations** caused memory spikes
3. **No upper bounds** on any data structures
4. **Garbage collection** couldn't keep up with allocation rate

## üí° Solution Strategy

Based on the root cause analysis, the solution required:

1. **Bounded Data Structures**: Implement size limits on all collections
2. **Memory-Safe Serialization**: Chunk large objects and add size checks
3. **Pressure-Aware Eviction**: Monitor memory usage and proactively clean up
4. **Real-time Monitoring**: Track memory health continuously

## üéØ Validation Approach

- Memory stress tests with large datasets
- Laravel Scout integration test suite
- Long-running stability tests
- Memory usage profiling under load

---

*Analysis completed: May 23, 2025* 