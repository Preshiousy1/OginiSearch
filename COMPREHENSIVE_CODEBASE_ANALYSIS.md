# üîç Comprehensive Codebase Analysis: ConnectSearch/Ogini Search Engine

**Date:** December 2025  
**Analysis Type:** Full Architecture & Performance Review  
**Codebase State:** Current PostgreSQL-based implementation (main branch)  
**Status:** Significant performance issues identified - 6-22 second query times vs <200ms target

---

## üìä Executive Summary

### Current State
- **Architecture:** NestJS + PostgreSQL + Redis search engine
- **Document Count:** ~600K+ documents across multiple indices
- **Performance:** **CRITICAL** - 6-22 seconds average query time (target: <200ms)
- **Timeout Rate:** ~40% of queries timing out (>10 seconds)
- **Success Rate:** ~60% (40% failure due to timeouts)

### Root Cause Assessment
**PRIMARY ISSUE:** The architecture suffers from fundamental design flaws that cause catastrophic performance degradation as data scales:

1. **PostgreSQL Full-Text Search Misconfiguration** - Missing/incomplete search vector population
2. **JSONB-Heavy Design** - Over-reliance on JSONB without proper materialized columns
3. **Inefficient Query Patterns** - Complex CTEs, missing indexes, sequential scans
4. **Architectural Mismatch** - Using PostgreSQL as a document store without proper optimization

### Key Findings
- **Design Shortfall:** System was designed with MongoDB-style flexibility but migrated to PostgreSQL without adapting the data model
- **Index Strategy Failure:** Critical GIN indexes missing or ineffective
- **Query Pattern Issues:** Complex CTEs materializing entire result sets instead of using indexes
- **Caching Ineffective:** Redis caching exists but misses are expensive due to slow base queries

---

## üõ† Technology Stack

### Core Framework
- **Runtime:** Node.js 18+ (TypeScript)
- **Framework:** NestJS 11.x (Express-based)
- **Language:** TypeScript 5.1.6

### Database & Storage
- **Primary Database:** PostgreSQL 13+ with full-text search (tsvector/tsquery)
- **Extensions Used:**
  - `pg_trgm` (trigram matching)
  - `unaccent` (accent-insensitive search)
  - `pg_stat_statements` (query monitoring)
  - `vector` (pgvector for semantic search - optional)
- **Caching:** Redis 6+ via ioredis (with Bull queue integration)
- **Queue System:** Bull 4.12.2 (Redis-based job queue)

### Key Dependencies
- **ORM:** TypeORM 0.3.25
- **Database Driver:** pg 8.16.3
- **Analysis:** Porter Stemmer, dictionary-en, mnemonist
- **Text Processing:** Custom analyzers, tokenizers, filters

### Infrastructure
- **Containerization:** Docker (Dockerfile + docker-compose)
- **Deployment:** Railway-ready configuration
- **Monitoring:** Grafana + Prometheus (optional, configured)

---

## üèó Architecture Overview

### High-Level Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      Client Application                      ‚îÇ
‚îÇ                    (Laravel Backend cn2.0-be)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ HTTP/REST API
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   NestJS API Layer                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ   Search     ‚îÇ  ‚îÇ  Document    ‚îÇ  ‚îÇ   Bulk       ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  Controller  ‚îÇ  ‚îÇ  Controller  ‚îÇ  ‚îÇ  Indexing    ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                  ‚îÇ                 ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Service Layer                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  SearchService                                       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ EntityExtractionService                         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ LocationProcessorService                        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ QueryExpansionService                           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ GeographicFilterService                         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ MultiSignalRankingService                       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ TieredRankingService                            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ TypoToleranceService                            ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  PostgreSQLSearchEngine                              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ Query building & execution                       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ Result processing                                ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ Index management                                 ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Storage Layer (PostgreSQL)                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  documents table (600K+ rows)                        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ content (JSONB) - document data                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ search_vector (tsvector) - full-text index      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ materialized_vector (tsvector) - optimized      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ metadata (JSONB)                                ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Redis Cache Layer                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Query result caching (5 min TTL)                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Bull queue for bulk indexing                        ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Module Structure

The application follows NestJS modular architecture:

1. **AppModule** - Root module, configures global modules
2. **ApiModule** - REST API controllers and DTOs
3. **SearchModule** - Search orchestration and intelligence services
4. **StorageModule** - PostgreSQL integration and document storage
5. **IndexingModule** - Document processing and indexing pipeline
6. **AnalysisModule** - Text analysis (tokenizers, analyzers, filters)
7. **SchemaModule** - Index schema and mapping management

---

## üîß Core Components & Services

### Search Flow Components

#### 1. SearchController (`src/api/controllers/search.controller.ts`)
- **Purpose:** HTTP endpoint handler for search requests
- **Endpoint:** `POST /api/indices/:index/_search`
- **Flow:** Request ‚Üí SearchService ‚Üí Response
- **Issues:** Minimal validation, no request deduplication

#### 2. SearchService (`src/search/search.service.ts`)
- **Purpose:** Main search orchestration service
- **Responsibilities:**
  - Query processing pipeline orchestration
  - Cache management (Redis)
  - Typo tolerance coordination
  - Entity extraction
  - Result aggregation and formatting
- **Dependencies:** 8+ service dependencies creating tight coupling
- **Issues:** 
  - Complex dependency graph
  - Sequential processing when parallel would be faster
  - Cache miss handling expensive

#### 3. PostgreSQLSearchEngine (`src/storage/postgresql/postgresql-search-engine.ts`)
- **Purpose:** Direct PostgreSQL query execution
- **Size:** ~1490 lines - **TOO LARGE** (should be split)
- **Responsibilities:**
  - SQL query building
  - Search vector management
  - Index validation
  - Document CRUD operations
- **Critical Issues:**
  - Complex query building with multiple fallback paths
  - Missing index utilization in many queries
  - JSONB extraction in WHERE clauses
  - Inconsistent vector usage (`search_vector` vs `materialized_vector` vs `weighted_search_vector`)

### Indexing Flow Components

#### 1. BulkIndexingController (`src/api/controllers/bulk-indexing.controller.ts`)
- **Purpose:** Queue bulk indexing jobs
- **Endpoint:** `POST /bulk-indexing/queue/batch`
- **Flow:** Documents ‚Üí Bull Queue ‚Üí IndexingQueueProcessor

#### 2. BulkIndexingService (`src/indexing/services/bulk-indexing.service.ts`)
- **Purpose:** Queue management for bulk operations
- **Features:** Batch splitting, job tracking, retry logic
- **Issues:** No rate limiting, potential queue buildup

#### 3. IndexingQueueProcessor (`src/indexing/queue/indexing-queue.processor.ts`)
- **Purpose:** Bull queue processor for indexing jobs
- **Processes:** Single documents and batches
- **Flow:** Job ‚Üí DocumentService ‚Üí IndexingService ‚Üí PostgreSQL
- **Issues:** 
  - Batch processing does sub-batching (100 docs at a time)
  - Individual error handling may be inefficient
  - No progress tracking for large batches

#### 4. DocumentService (`src/document/document.service.ts`)
- **Purpose:** Document storage and retrieval
- **Features:** Bulk operations, field mapping detection
- **Issues:** Auto-detection may cause mapping inconsistencies

#### 5. IndexingService (`src/indexing/indexing.service.ts`)
- **Purpose:** Document processing and index updates
- **Flow:** Document ‚Üí Processing ‚Üí Storage ‚Üí Index Update
- **Issues:** Single document focus, no batch optimizations

### Text Analysis Components

#### AnalysisModule (`src/analysis/`)
- **Purpose:** Text tokenization, normalization, stemming
- **Components:**
  - StandardTokenizer, NGramTokenizer, WhitespaceTokenizer
  - StandardAnalyzer, KeywordAnalyzer, CustomAnalyzer
  - LowercaseFilter, StopwordFilter, StemmingFilter
- **Status:** Well-tested, production-ready
- **Issue:** Not fully utilized in PostgreSQL path (PostgreSQL has its own tokenization)

---

## üìä Data Flow: Indexing Pipeline

### Document Indexing Flow

```
1. Document Received (via API)
   ‚îÇ
   ‚îú‚îÄ‚Üí BulkIndexingController.queueBatchDocuments()
   ‚îÇ   ‚îú‚îÄ Validates documents array
   ‚îÇ   ‚îî‚îÄ Calls BulkIndexingService.queueBulkIndexing()
   ‚îÇ
2. Queue Management
   ‚îÇ
   ‚îú‚îÄ‚Üí BulkIndexingService.queueBulkIndexing()
   ‚îÇ   ‚îú‚îÄ Splits into batches (default: 1000 docs/batch)
   ‚îÇ   ‚îî‚îÄ Adds jobs to Bull queue ('bulk-indexing')
   ‚îÇ
3. Queue Processing (Async)
   ‚îÇ
   ‚îú‚îÄ‚Üí IndexingQueueProcessor.processBatchDocuments()
   ‚îÇ   ‚îú‚îÄ Validates index exists
   ‚îÇ   ‚îú‚îÄ Auto-detects field mappings (ensureFieldMappings)
   ‚îÇ   ‚îî‚îÄ Calls DocumentService.bulkStoreDocuments()
   ‚îÇ
4. Document Storage
   ‚îÇ
   ‚îú‚îÄ‚Üí DocumentService.bulkStoreDocuments()
   ‚îÇ   ‚îú‚îÄ Stores in PostgreSQL 'documents' table
   ‚îÇ   ‚îú‚îÄ JSONB content column
   ‚îÇ   ‚îú‚îÄ Generates search_vector (tsvector)
   ‚îÇ   ‚îî‚îÄ Handles duplicates (ON CONFLICT UPDATE)
   ‚îÇ
5. Search Indexing (if needed)
   ‚îÇ
   ‚îî‚îÄ‚Üí IndexingService.indexDocument()
       ‚îú‚îÄ DocumentProcessorService.processDocument()
       ‚îÇ   ‚îú‚îÄ Tokenization
       ‚îÇ   ‚îú‚îÄ Normalization
       ‚îÇ   ‚îî‚îÄ Term extraction
       ‚îî‚îÄ IndexStorage.storeProcessedDocument()
           ‚îî‚îÄ Updates term dictionary and postings
```

### Critical Issues in Indexing Flow

1. **Dual Storage Pattern Confusion**
   - Documents stored in PostgreSQL `documents` table
   - Separate inverted index maintained in memory/other storage
   - Creates data synchronization issues
   - PostgreSQL search uses `search_vector`, inverted index uses term dictionaries

2. **Search Vector Generation**
   - Generated during insert but may be incomplete
   - `materialized_vector` vs `search_vector` inconsistency
   - `weighted_search_vector` not always populated
   - Triggers may be too slow for bulk operations

3. **No Batch Optimization**
   - Each document processed individually in many paths
   - Missing bulk UPDATE statements for vectors
   - No transaction batching for better performance

---

## üîç Data Flow: Search Pipeline

### Search Query Flow

```
1. Search Request
   ‚îÇ
   ‚îú‚îÄ‚Üí SearchController.search()
   ‚îÇ   ‚îú‚îÄ Receives SearchQueryDto
   ‚îÇ   ‚îî‚îÄ Calls SearchService.search()
   ‚îÇ
2. Cache Check
   ‚îÇ
   ‚îú‚îÄ‚Üí SearchService.search()
   ‚îÇ   ‚îú‚îÄ Generates Redis cache key
   ‚îÇ   ‚îú‚îÄ Checks Redis cache
   ‚îÇ   ‚îî‚îÄ Returns cached result if found
   ‚îÇ
3. Query Processing (if cache miss)
   ‚îÇ
   ‚îú‚îÄ‚Üí Parallel Processing:
   ‚îÇ   ‚îú‚îÄ DictionaryService.isQueryLikelyCorrect() (typo check)
   ‚îÇ   ‚îú‚îÄ EntityExtractionService.extractEntities()
   ‚îÇ   ‚îú‚îÄ LocationProcessorService.processLocationQuery()
   ‚îÇ   ‚îî‚îÄ QueryExpansionService.expandQuery()
   ‚îÇ
4. PostgreSQL Query Execution
   ‚îÇ
   ‚îú‚îÄ‚Üí PostgreSQLSearchEngine.search()
   ‚îÇ   ‚îú‚îÄ buildOptimizedSingleQuery() - Builds SQL
   ‚îÇ   ‚îú‚îÄ buildCountQuery() - Builds count SQL
   ‚îÇ   ‚îî‚îÄ Executes both in parallel
   ‚îÇ
5. SQL Query Structure (Current - PROBLEMATIC)
   ‚îÇ
   ‚îú‚îÄ‚Üí WITH field_rankings AS (
   ‚îÇ       SELECT
   ‚îÇ         CASE WHEN content->>'name' ILIKE ... -- JSONB extraction
   ‚îÇ         CASE WHEN content->>'category' ILIKE ... -- JSONB extraction
   ‚îÇ         ts_rank_cd(...) as rank
   ‚îÇ       FROM documents
   ‚îÇ       WHERE search_vector @@ to_tsquery(...)
   ‚îÇ     )
   ‚îÇ     SELECT * FROM field_rankings ORDER BY rank DESC
   ‚îÇ
6. Result Processing
   ‚îÇ
   ‚îú‚îÄ‚Üí GeographicFilterService.filterResults()
   ‚îú‚îÄ‚Üí MultiSignalRankingService.rankResults()
   ‚îú‚îÄ‚Üí TieredRankingService.adjustRanking()
   ‚îî‚îÄ‚Üí Format response
   ‚îÇ
7. Cache Storage
   ‚îÇ
   ‚îî‚îÄ‚Üí RedisCacheService.set() - Store result for 5 minutes
```

### Critical Issues in Search Flow

1. **Query Building Complexity**
   - Multiple fallback paths (materialized_vector ‚Üí search_vector ‚Üí JSONB ILIKE)
   - Complex CTEs materializing entire result sets
   - JSONB extraction in SELECT and WHERE clauses
   - No query plan caching

2. **Missing Index Utilization**
   - GIN indexes exist but queries don't use them effectively
   - `ILIKE '%term%'` patterns can't use B-tree indexes
   - No trigram index usage for pattern matching
   - Filter conditions extract JSONB instead of using materialized columns

3. **Over-Processing**
   - Entity extraction, location processing, query expansion run on every query
   - Even for simple term searches that don't need intelligence
   - Typo tolerance adds 100-500ms overhead unnecessarily

4. **Sequential Processing**
   - Some operations that could be parallel are sequential
   - No query deduplication (same query across indices executed separately)

---

## üíæ Database Schema & Storage

### Current Schema Structure

#### documents Table
```sql
CREATE TABLE documents (
    document_id VARCHAR(255) NOT NULL,
    index_name VARCHAR(255) NOT NULL,
    content JSONB NOT NULL,                    -- Full document data
    metadata JSONB NOT NULL DEFAULT '{}',      -- Additional metadata
    search_vector TSVECTOR NOT NULL,          -- Full-text search index
    materialized_vector TSVECTOR,             -- Optimized vector (nullable)
    field_weights JSONB NOT NULL DEFAULT '{}', -- Field weighting config
    created_at TIMESTAMP WITH TIME ZONE,
    updated_at TIMESTAMP WITH TIME ZONE,
    PRIMARY KEY (document_id, index_name)
);
```

#### indices Table
```sql
CREATE TABLE indices (
    index_name VARCHAR(255) PRIMARY KEY,
    settings JSONB NOT NULL DEFAULT '{}',     -- Index configuration
    status VARCHAR(50) NOT NULL DEFAULT 'open',
    document_count INTEGER NOT NULL DEFAULT 0,
    created_at TIMESTAMP WITH TIME ZONE,
    updated_at TIMESTAMP WITH TIME ZONE
);
```

### Schema Design Issues

#### 1. **JSONB-Heavy Design** üî¥ CRITICAL
**Problem:** Entire document stored in `content` JSONB column
- **Impact:** JSONB extraction on every query: `content->>'name'`
- **Performance:** 5-10x slower than indexed columns
- **No Indexes:** Can't create efficient indexes on JSONB paths
- **Size:** JSONB compression/overhead for frequently accessed fields

**Evidence:**
- Queries extract 5-10 JSONB fields per document
- Filter conditions: `(content->>'is_active')::boolean = true`
- Sorting on extracted fields: `ORDER BY content->>'name'`

**Should Be:**
```sql
-- Materialized columns for frequently queried fields
name TEXT GENERATED ALWAYS AS (content->>'name') STORED,
category TEXT GENERATED ALWAYS AS (content->>'category_name') STORED,
is_active BOOLEAN GENERATED ALWAYS AS ((content->>'is_active')::boolean) STORED
```

#### 2. **Inconsistent Vector Usage** üî¥ CRITICAL
**Problem:** Three different vector columns with unclear purpose
- `search_vector` - Basic tsvector (always populated)
- `materialized_vector` - Optimized tsvector (nullable, not always populated)
- `weighted_search_vector` - Mentioned in queries but not in schema

**Impact:**
- Queries use `COALESCE(materialized_vector, search_vector)` causing planner confusion
- Some documents have vectors, some don't
- Inconsistent ranking scores

**Evidence from Code:**
```typescript
// PostgreSQLSearchEngine - inconsistent usage
ts_rank_cd(COALESCE(d.materialized_vector, d.search_vector), ...)
weighted_search_vector @@ plainto_tsquery(...)  // Column doesn't exist!
```

#### 3. **Missing Critical Indexes** üî¥ CRITICAL
**Problem:** GIN indexes for tsvector not consistently created or used
- `idx_documents_search_vector` - May be missing or ineffective
- `idx_documents_materialized_vector` - May be missing
- No trigram indexes for pattern matching
- No expression indexes for JSONB extractions

**Impact:** Sequential scans on 600K+ rows = 10-20 second queries

#### 4. **No Partitioning** üü† HIGH
**Problem:** Single monolithic table for all indices
- All queries scan entire table
- No locality of reference
- Vacuum/analyze operations affect all indices

**Should Be:**
```sql
-- Partition by index_name
CREATE TABLE documents PARTITION BY LIST (index_name);
```

#### 5. **Index Metadata Separation** üü° MEDIUM
**Problem:** Index metadata stored separately from documents
- Requires joins for some queries
- Index stats may be stale
- No atomic updates

---

## üö® Performance Issues & Design Problems

### Issue #1: Missing/Incomplete Search Vector Population üî¥ CRITICAL
**Impact:** 90% of performance degradation

**Root Cause:**
1. Vectors not populated during bulk indexing
2. Trigger-based generation too slow for large datasets
3. No batch processing for vector generation
4. Inconsistent vector column usage

**Evidence:**
```sql
-- Many documents have NULL or empty vectors
SELECT 
  COUNT(*) as total,
  COUNT(search_vector) as has_search_vector,
  COUNT(materialized_vector) as has_materialized
FROM documents
GROUP BY index_name;
-- Result: has_materialized << total
```

**Impact:**
- Queries fall back to JSONB ILIKE (10-50x slower)
- Can't use GIN indexes effectively
- Full table scans required

**Solution Status:** Partially addressed - optimization script exists but not consistently applied

---

### Issue #2: Inefficient JSONB Querying üî¥ CRITICAL
**Impact:** 50-70% performance hit on every query

**Problem:**
```sql
-- Every search extracts JSONB fields on the fly
SELECT 
  content->>'name' as name,
  content->>'category_name' as category
FROM documents
WHERE content->>'name' ILIKE '%term%'
```

**Why This Kills Performance:**
1. **No GIN indexes on JSONB paths** - Each extraction requires full decompression
2. **ILIKE on JSONB** - Can't use indexes effectively
3. **Multiple JSONB extractions per row** - 5-10 extractions per document
4. **No expression indexes** - PostgreSQL can't optimize these patterns

**Benchmark:**
- JSONB extraction + ILIKE: ~10-50ms per 1000 rows
- Indexed tsvector search: ~1-5ms per 1000 rows
- **10-50x performance difference**

**Solution Status:** Materialized columns created by optimization script, but queries not updated to use them consistently

---

### Issue #3: Query Plan Catastrophe - Complex CTEs üî¥ CRITICAL
**Impact:** 30-50% overhead per query

**Problem:**
```sql
WITH field_rankings AS (
  SELECT
    -- 5+ CASE statements per row
    CASE WHEN content->>'name' ILIKE ... -- Extract 1
    CASE WHEN content->>'category' ILIKE ... -- Extract 2
    CASE WHEN content->>'description' ILIKE ... -- Extract 3
    -- Plus ts_rank_cd calculation
  FROM documents
  WHERE -- Complex filter conditions
)
SELECT * FROM field_rankings
ORDER BY rank DESC
```

**Why This Is Terrible:**
1. **Materialization overhead** - CTE forces PostgreSQL to materialize entire result set
2. **Multiple CASE evaluations** - 5+ CASE statements per row
3. **JSONB decompression repeated** - Same field extracted multiple times
4. **No intermediate result reuse** - Each CASE statement re-extracts

**Current State:** Partially addressed - some queries simplified, but complex patterns remain

---

### Issue #4: Wildcard Query Implementation Disaster üî¥ CRITICAL
**Impact:** Queries with wildcards 5-10x slower

**Problem:**
- Wildcards treated as literals: `"accurate*"` searched as literal asterisk
- `ILIKE '%...%'` can't use B-tree indexes ‚Üí sequential scan
- No pg_trgm optimization despite extension installed
- Pattern matching on JSONB (worst possible combination)

**Evidence from Logs:**
- `"accurate* predict*"` takes 22 seconds for 2 results
- `"fazsion*"` takes 15 seconds for 1 result
- Both should be <100ms

**Solution Status:** Wildcard handling exists but ineffective

---

### Issue #5: Duplicate Search Execution üü† HIGH
**Impact:** 2x total time for multi-index searches

**Problem:**
```
3:18:49 - Search for 'fazsion*' in businesses: 15645ms
3:18:56 - IMMEDIATELY search 'fazsion*' in listings: 6136ms
Total: 21781ms for same query across indices
```

**Root Cause:**
- No query deduplication
- Searches multiple indices sequentially instead of parallel
- Cache not effective (searches same query twice)
- Frontend may be making duplicate requests

**Solution Status:** Not addressed

---

### Issue #6: Filter Condition Overhead üü† HIGH
**Impact:** 20-40% per query with filters

**Problem:**
```sql
WHERE index_name = $1
  AND (content->>'is_active')::boolean = true
  AND (content->>'is_verified')::boolean = true  
  AND (content->>'is_blocked')::boolean = false
```

**Why Slow:**
1. **No indexes on filter columns** - Each filter requires full table scan
2. **Type casting in WHERE clause** - `::boolean` prevents index usage
3. **Multiple JSONB extractions** - 3+ extractions per row for filters
4. **AND conditions not short-circuited** - All evaluated even if first fails

**Solution Status:** Materialized columns created, but queries not fully updated

---

### Issue #7: No Table Partitioning üü° MEDIUM
**Impact:** 15-30% on large datasets

**Problem:**
- Single `documents` table with 600K+ rows
- No partitioning by `index_name` or date
- All queries scan entire table

**Impact:**
- Query planner can't eliminate partitions
- Indexes must cover entire table
- No locality of reference
- Vacuum and analyze take longer

**Solution Status:** Not implemented

---

### Issue #8: Connection Pool Saturation üü° MEDIUM
**Impact:** Variable, causes cascading failures

**Current Config:**
```typescript
max: 100,              // Recently increased from 25
min: 20,               // Recently increased from 10
acquireTimeoutMillis: 10000,  // Recently increased from 5000
```

**Problems:**
1. **Still too small for concurrent load** - 100 connections may not be enough
2. **10s acquisition timeout** - Still causes additional delays
3. **No connection validation** - Stale connections not detected
4. **PgBouncer not optimized** - Another layer of overhead

**Solution Status:** Improved but may need further tuning

---

### Issue #9: Typo Tolerance Overhead üü° MEDIUM
**Impact:** 100-500ms additional latency

**Problem:**
- SymSpell index not properly maintained
- Dictionary checks add latency
- Typo correction attempted even when not needed
- No async processing

**Solution Status:** Partially optimized - parallel processing added, but still adds overhead

---

### Issue #10: Service Layer Complexity üü° MEDIUM
**Impact:** Maintenance burden, potential bugs

**Problem:**
- **SearchService has 8+ dependencies** - Tight coupling
- **PostgreSQLSearchEngine is 1490 lines** - Too large, violates SRP
- **Multiple ranking services** - TieredRankingService, MultiSignalRankingService, BM25RankingService
- **Inconsistent error handling** - Some services throw, others return null

**Impact:**
- Hard to test
- Hard to maintain
- Potential for bugs when making changes
- Difficult to optimize individual components

---

## üéØ Technology Choices Analysis

### PostgreSQL as Search Engine: ‚ö†Ô∏è MIXED

**Pros:**
- ‚úÖ ACID compliance
- ‚úÖ Full-text search built-in (tsvector/tsquery)
- ‚úÖ Mature and stable
- ‚úÖ Good tooling and monitoring

**Cons:**
- ‚ùå **Not designed for document search** - PostgreSQL is relational, not document-oriented
- ‚ùå **JSONB overhead** - Storing entire documents in JSONB is inefficient
- ‚ùå **Full-text search limitations** - Not as flexible as dedicated search engines (Elasticsearch, Algolia)
- ‚ùå **Scaling challenges** - Horizontal scaling more complex than NoSQL

**Verdict:** PostgreSQL can work for search, but requires careful optimization. The current implementation doesn't leverage PostgreSQL's strengths (relational model, materialized views) and instead fights against its weaknesses (JSONB extraction, document-oriented patterns).

---

### NestJS Framework: ‚úÖ GOOD

**Pros:**
- ‚úÖ Well-structured modular architecture
- ‚úÖ Dependency injection promotes testability
- ‚úÖ TypeScript support
- ‚úÖ Good ecosystem

**Cons:**
- ‚ö†Ô∏è Module dependencies can create circular dependencies (some evidence in codebase)
- ‚ö†Ô∏è Service layer complexity (8+ dependencies per service)

**Verdict:** Good choice, but complexity management could be better

---

### Bull Queue for Indexing: ‚úÖ GOOD

**Pros:**
- ‚úÖ Reliable job processing
- ‚úÖ Built-in retry logic
- ‚úÖ Progress tracking capabilities
- ‚úÖ Redis-based (consistent with caching)

**Cons:**
- ‚ö†Ô∏è Redis dependency (single point of failure if not configured for HA)
- ‚ö†Ô∏è Queue can build up under high load (no rate limiting)

**Verdict:** Appropriate choice for async indexing tasks

---

### Redis Caching: ‚ö†Ô∏è UNDERUTILIZED

**Pros:**
- ‚úÖ Fast key-value storage
- ‚úÖ Good for caching query results
- ‚úÖ TTL support

**Cons:**
- ‚ùå **Cache misses are expensive** - Slow base queries make caching less effective
- ‚ùå **No cache warming strategy** - Cache only populated on first query
- ‚ùå **Simple cache key generation** - May cause cache thrashing

**Verdict:** Good infrastructure choice, but not effectively utilized due to slow base queries

---

### TypeORM: ‚ö†Ô∏è LIMITED USAGE

**Observation:**
- TypeORM entities defined but most queries use raw SQL
- Little benefit from ORM features
- Entities exist but `DataSource.query()` used directly

**Verdict:** Using TypeORM but not leveraging its benefits. Raw SQL is fine, but adds maintenance burden.

---

## üìà System Flow Decisions & Their Impact

### Decision #1: Store Everything in JSONB
**Decision:** Store complete documents in `content` JSONB column
**Rationale:** Flexibility, schema-less design like MongoDB
**Impact:** üî¥ **NEGATIVE**
- 50-70% performance degradation on every query
- Can't create efficient indexes
- JSONB extraction overhead
- No type safety

**Alternative:** Materialized columns for frequently queried fields

---

### Decision #2: Dual Storage Pattern (PostgreSQL + Inverted Index)
**Decision:** Maintain documents in PostgreSQL AND separate inverted index
**Rationale:** Hybrid approach for flexibility
**Impact:** üî¥ **NEGATIVE**
- Data synchronization complexity
- Double storage overhead
- Inconsistent results if sync fails
- Unclear which system is source of truth

**Alternative:** Single source of truth (PostgreSQL only OR inverted index only)

---

### Decision #3: Complex Service Layer
**Decision:** Multiple specialized services (EntityExtraction, LocationProcessor, etc.)
**Rationale:** Separation of concerns, modularity
**Impact:** ‚ö†Ô∏è **MIXED**
- **Pros:** Clean separation, testable components
- **Cons:** Overhead on every query (even simple ones), tight coupling, complex dependency graph

**Alternative:** Conditional service invocation - only run intelligent services for complex queries

---

### Decision #4: Bull Queue for Bulk Indexing
**Decision:** Use Bull queue with Redis for async document indexing
**Rationale:** Handle large batches without blocking API
**Impact:** ‚úÖ **POSITIVE**
- Allows async processing
- Retry logic built-in
- Progress tracking possible

**Issues:**
- Queue can build up under high load
- No rate limiting
- Individual error handling may be inefficient for large batches

---

### Decision #5: PostgreSQL Full-Text Search Only
**Decision:** Use PostgreSQL tsvector/tsquery instead of dedicated search engine
**Rationale:** Single database, ACID compliance, reduce infrastructure
**Impact:** ‚ö†Ô∏è **MIXED**
- **Pros:** Simpler infrastructure, ACID compliance, no separate search cluster
- **Cons:** Less flexible than Elasticsearch/Algolia, requires careful optimization (not done), scaling challenges

**Alternative:** Use dedicated search engine (Elasticsearch, Meilisearch, Typesense) for search, PostgreSQL for document storage

---

### Decision #6: Auto-Detection of Field Mappings
**Decision:** Automatically detect document fields and create mappings during indexing
**Rationale:** Flexible schema, no pre-configuration needed
**Impact:** ‚ö†Ô∏è **MIXED**
- **Pros:** Easy to get started, handles varying document structures
- **Cons:** Mapping inconsistencies, no validation, performance impact during detection

---

### Decision #7: Multiple Ranking Services
**Decision:** Separate services for BM25, MultiSignal, and Tiered ranking
**Rationale:** Different ranking strategies for different scenarios
**Impact:** ‚ö†Ô∏è **MIXED**
- **Pros:** Flexible ranking strategies
- **Cons:** Complex decision logic, potential conflicts, over-engineering for current needs

---

### Decision #8: In-Memory Index Cache
**Decision:** Cache index metadata in memory (`Map<string, IndexConfig>`)
**Rationale:** Fast lookups without database queries
**Impact:** ‚úÖ **POSITIVE** but limited
- Reduces database roundtrips for index validation
- Simple implementation
- Limited to metadata only, not search results

---

### Decision #9: Raw SQL Over TypeORM Query Builder
**Decision:** Use `DataSource.query()` with raw SQL instead of TypeORM query builder
**Rationale:** More control, better performance, complex queries easier
**Impact:** ‚ö†Ô∏è **MIXED**
- **Pros:** Full SQL control, can optimize directly, handles complex queries
- **Cons:** No type safety, harder to maintain, SQL injection risk if not careful, harder to test

---

### Decision #10: Single Table for All Indices
**Decision:** Store all documents from all indices in single `documents` table
**Rationale:** Simpler schema, easier management
**Impact:** üî¥ **NEGATIVE**
- No data locality
- All queries scan full table
- Can't partition by index efficiently
- Index maintenance affects all indices

**Alternative:** Separate tables per index OR partitioned table by index_name

---

## üéØ Critical Design Shortfalls Summary

### 1. **MongoDB-to-PostgreSQL Migration Without Adaptation** üî¥
**Issue:** System appears to have been migrated from MongoDB architecture to PostgreSQL without adapting the data model
- MongoDB-style JSONB storage without leveraging PostgreSQL strengths
- No materialized columns for frequently queried fields
- Missing relational design patterns

**Impact:** 50-70% performance degradation

---

### 2. **Inverted Index Confusion** üî¥
**Issue:** Dual storage pattern - documents in PostgreSQL AND separate inverted index
- Two sources of truth
- Synchronization overhead
- Unclear which system handles what

**Impact:** Complexity, potential data inconsistency, maintenance burden

---

### 3. **Search Vector Inconsistency** üî¥
**Issue:** Three different vector columns (`search_vector`, `materialized_vector`, `weighted_search_vector`)
- Unclear which to use when
- Inconsistent population
- Queries use COALESCE causing planner confusion

**Impact:** 90% of performance issues - queries can't use indexes effectively

---

### 4. **No Query Optimization Strategy** üî¥
**Issue:** Queries built dynamically without optimization
- Complex CTEs materializing entire result sets
- JSONB extraction in WHERE clauses
- No query plan analysis
- Missing indexes despite having optimization scripts

**Impact:** 10-20 second query times instead of <200ms

---

### 5. **Over-Engineering for Simple Queries** üü†
**Issue:** Intelligent services run on every query regardless of complexity
- Entity extraction for simple term searches
- Location processing when no location in query
- Query expansion for exact matches
- Typo tolerance when query is correct

**Impact:** 100-500ms overhead on simple queries

---

### 6. **No Caching Strategy** üü†
**Issue:** Redis caching exists but no intelligent strategy
- No cache warming
- Simple key generation (may cause thrashing)
- No cache invalidation strategy
- Cache misses are expensive due to slow base queries

**Impact:** Cache helps but doesn't solve fundamental performance issues

---

### 7. **Index Strategy Failure** üî¥
**Issue:** Critical indexes missing or ineffective
- GIN indexes not consistently created
- No trigram indexes for pattern matching
- No materialized columns indexed
- Filter columns not indexed

**Impact:** Sequential scans on 600K+ rows = 10-20 second queries

---

### 8. **Connection Management** üü°
**Issue:** Connection pool settings may not be optimal
- Recent increases from 25‚Üí100 but may need more
- No connection validation
- PgBouncer overhead not optimized

**Impact:** Connection saturation under load

---

### 9. **Error Handling Inconsistency** üü°
**Issue:** Different services handle errors differently
- Some throw exceptions
- Some return null
- Some return empty arrays
- No standardized error handling

**Impact:** Hard to debug, unpredictable behavior

---

### 10. **No Monitoring/Alerting** üü°
**Issue:** Performance monitoring exists but not actively used
- `pg_stat_statements` configured but not monitored
- Slow query logging exists but not acted upon
- No alerts for performance degradation

**Impact:** Performance issues not detected early

---

## üìã Architecture Comparison Points (For Future MongoDB Comparison)

### Areas to Compare:

1. **Data Model**
   - MongoDB: Document-oriented, flexible schema
   - Current PostgreSQL: JSONB documents in relational table
   - Legacy MongoDB: Unknown - needs analysis

2. **Indexing Strategy**
   - Current: PostgreSQL tsvector + inverted index (confused)
   - Legacy: Need to analyze

3. **Query Performance**
   - Current: 6-22 seconds (critical issues)
   - Legacy: Unknown - needs comparison

4. **Storage Efficiency**
   - Current: JSONB overhead + dual storage
   - Legacy: Need to analyze

5. **Scalability**
   - Current: Vertical scaling only, connection pool limits
   - Legacy: Need to analyze

---

## üîç Code Quality Observations

### Strengths ‚úÖ

1. **TypeScript Usage:** Strong type safety throughout
2. **Modular Structure:** Clean NestJS module separation
3. **Error Logging:** Comprehensive logging with Winston
4. **Configuration Management:** Environment-based config via ConfigModule
5. **Test Coverage:** Some test files present (need to verify coverage %)
6. **Documentation:** API documentation via Swagger

### Weaknesses ‚ùå

1. **Large Service Files:** `PostgreSQLSearchEngine` is 1490 lines (should be <300)
2. **Complex Dependencies:** `SearchService` has 8+ dependencies
3. **Code Duplication:** Similar query building logic repeated
4. **Magic Strings:** Hardcoded SQL fragments, index names
5. **Inconsistent Patterns:** Some services use async/await, others use callbacks
6. **Missing Tests:** Many services lack unit tests
7. **Technical Debt:** Multiple `.backup` files indicate refactoring in progress

---

## üìä Performance Benchmarks (Current State)

### Query Performance Metrics

| Query Type | Current Performance | Target | Degradation Factor |
|------------|---------------------|--------|-------------------|
| Simple term search | 3-8 seconds | <50ms | **60-160x** |
| Wildcard search | 7-15 seconds | <100ms | **70-150x** |
| Multi-term search | 10-22 seconds | <200ms | **50-110x** |
| Filtered search | 6-20 seconds | <150ms | **40-133x** |
| Exact match | 1-3 seconds | <20ms | **50-150x** |

### Database Metrics

| Metric | Value | Status |
|--------|-------|--------|
| Total Documents | ~600K+ | High |
| Documents per Index | Varies (100K+) | High |
| Index Count | Multiple | Normal |
| Query Timeout Rate | ~40% | üî¥ Critical |
| Cache Hit Rate | ~20% | ‚ö†Ô∏è Low |
| Connection Pool Utilization | Unknown | Needs monitoring |

---

## üéØ Recommendations for Architecture Comparison

When comparing with the MongoDB legacy architecture, focus on:

1. **Query Performance:** What were query times in MongoDB version?
2. **Data Model:** How was data structured in MongoDB?
3. **Indexing:** What indexing strategy was used?
4. **Scaling:** How did MongoDB version handle scale?
5. **Complexity:** Which version is simpler to maintain?
6. **Feature Set:** What features exist in each?
7. **Resource Usage:** Memory, CPU, storage comparison

---

## üìù Conclusion

### Current Architecture Assessment

The ConnectSearch/Ogini search engine in its current PostgreSQL implementation suffers from **fundamental architectural mismatches** that cause severe performance degradation:

1. **PostgreSQL is being used as a document store** without leveraging its relational strengths
2. **JSONB-heavy design** creates unnecessary overhead on every query
3. **Search vectors are inconsistently populated**, preventing index usage
4. **Query patterns fight against PostgreSQL** instead of working with it
5. **Over-engineering** adds complexity without performance benefit

### Key Takeaways

- **Not a PostgreSQL problem** - PostgreSQL can handle search well with proper optimization
- **Not a scale problem** - 600K documents is well within PostgreSQL's capabilities
- **It's a design problem** - The architecture needs fundamental rethinking

### Next Steps

1. **Compare with MongoDB legacy architecture** to understand design decisions
2. **Identify what worked** in the previous implementation
3. **Determine optimal path forward** - fix PostgreSQL or return to MongoDB or hybrid
4. **Focus on query patterns** - optimize the 20% of queries that cause 80% of load

---

## üìö References & Related Documentation

- `CRITICAL_SEARCH_PERFORMANCE_ANALYSIS.md` - Detailed performance issues
- `PERFORMANCE_ISSUES_TRACKER.md` - Tracked performance fixes
- `ENTERPRISE_SUB_50MS_OPTIMIZATION_PLAN.md` - Optimization strategies
- `scripts/complete-search-optimization.sql` - Database optimization script

---

**Document Status:** Complete  
**Next Action:** Compare with MongoDB legacy architecture (`legacy-mongodb-architecture` branch)  
**Last Updated:** December 2025